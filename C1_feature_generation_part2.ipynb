{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " C1-feature-generation-part2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvivvi/kaggle-c1/blob/master/C1_feature_generation_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yiQ2nPeQXKw",
        "colab_type": "code",
        "outputId": "2be6ebf7-6317-4489-a443-eace5f69880b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import sys\n",
        "import os.path\n",
        "import json\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive') \n",
        "  if not os.path.isfile('SETTINGS.json'):\n",
        "       # hard coded data directory in drive is used if SETTINGS.json not present \n",
        "       config={}\n",
        "       config['DATA_DIR'] = '/content/gdrive/My Drive/kaggle-c1'\n",
        "       with open('SETTINGS.json', 'w') as outfile:\n",
        "         json.dump(config, outfile)\n",
        "\n",
        "with open('SETTINGS.json') as config_file:\n",
        "    config = json.load(config_file)\n",
        "\n",
        "DATA_DIR = config['DATA_DIR']\n",
        "\n",
        "print('Using DATA_DIR ', DATA_DIR)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Using DATA_DIR  /content/gdrive/My Drive/kaggle-c1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CY0RZpd88blS",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import sklearn\n",
        "import scipy.sparse \n",
        "from itertools import product\n",
        "import gc\n",
        "from tqdm import tqdm_notebook\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "49OLgASs-k6i",
        "colab": {}
      },
      "source": [
        "def downcast_dtypes(df):\n",
        "    '''\n",
        "        Changes column types in the dataframe: \n",
        "                \n",
        "                `float64` type to `float32`\n",
        "                `int64`   type to `int32`\n",
        "    '''\n",
        "    \n",
        "    # Select columns to downcast\n",
        "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
        "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
        "    \n",
        "    # Downcast\n",
        "    df[float_cols] = df[float_cols].astype(np.float32)\n",
        "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Nsvpauv0jpk",
        "colab": {}
      },
      "source": [
        "\n",
        "DATA_FOLDER = DATA_DIR\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pom61IuY3sgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data=pd.read_csv(DATA_FOLDER + '/all_data_with_category_targets.csv')\n",
        "# List of columns that we will use to create lags\n",
        "cols_to_shift = [col for col in all_data.columns.values if re.search('target',col)] \n",
        "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
        "shift_range = [2, 3, 4, 5,6,12]\n",
        "\n",
        "# create shifted versions of one column at time and write to disk\n",
        "# in order to keep memory consumption manageable\n",
        "\n",
        "for col in cols_to_rename:\n",
        "    print(col)\n",
        "    all_data=pd.read_csv(DATA_FOLDER + '/all_data_with_category_targets.csv')\n",
        "    all_data=all_data[index_cols+[col]]\n",
        "    all_data=downcast_dtypes(all_data)\n",
        "    gc.collect()\n",
        "    for month_shift in tqdm_notebook(shift_range):\n",
        "        train_shift = all_data[index_cols + [col]].copy()\n",
        "        train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
        "    \n",
        "        foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x==col else x\n",
        "        train_shift = train_shift.rename(columns=foo)\n",
        "\n",
        "        all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
        "        all_data=downcast_dtypes(all_data)\n",
        "\n",
        "        del train_shift\n",
        "        gc.collect()\n",
        "\n",
        "        # Don't use old data without enough lags in the past\n",
        "    all_data = all_data[all_data['date_block_num'] >= 12] \n",
        "    all_data.to_csv(DATA_FOLDER + '/' + col + '_lagged.csv')\n",
        "    \n",
        "    del all_data\n",
        "    gc.collect()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}