{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fixed and generated three feature subsets\n",
    "1. non-lagged + lagged textual features\n",
    "2. lagged {target,item,shop} + non-lagged basic categories\n",
    "3. lagged features within shop\n",
    "\n",
    "and three first level classifiers types for each\n",
    "* a.  CatBoost\n",
    "* b. RidgeCV \n",
    "* c. Random Forest (sklearn) \n",
    "\n",
    "we search for hyperarameters that are used for predicting a month \n",
    "based on twelve month history, with one month gap between training and prediction periods.\n",
    "\n",
    "This is a compromise of the prediction quality on the other hand, and not having the prediction \n",
    "quality and optimal hyperparameters vary too much over the training period when generating the first level predictions as input features of second stacking level.\n",
    "\n",
    "The search for hyperparameters is problematic in whole because the chosen validation scheme is lacking. There may not be\n",
    "too much that can be done, because the validation data necessarily has different distribution as the actual testing data.\n",
    "This is because the temporal nature of the prediction problem. The distributions slowly drift during cause of time. Therefore, \n",
    "it is good to have the validation period temporally close to the test period. On the other hand, data analysis shows strong seasonal=(yearly) effects. \n",
    "Predicting October sales based on previous year simply is a very different problem to predicting December sales, as sales figures seem to peak strongly in December and have special characteristics.\n",
    "\n",
    "We decide to search for such hyperparameters that maximise the quality of predictions (with\n",
    "reasonable computational burden) in the hold-out validation data of Oct 2015. This is despite the fact that we have seen in examples that\n",
    "such optimal model hyperparameters do not result in optimal prediction quality for Dec 2015.\n",
    "We specifically do not search for such hyperparameters (via a coross-validation scheme) that would maximise the quality of predictions during\n",
    "the training period, as the value of temporally distant predictions is questionable after because of the distribution shift throughtime.\n",
    "\n",
    "\n",
    "The parameters are used for\n",
    "a) creating submissions for ensembling using simple schemes\n",
    "b) generating level 2 input features for a stacking algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "CY0RZpd88blS",
    "outputId": "eeb875e8-6911-4c03-f3ef-1384b94be160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.18.1\n",
      "pandas 0.25.3\n",
      "scipy 1.4.1\n",
      "sklearn 0.22.1\n",
      "lightgbm 2.3.1\n",
      "catboost 0.22\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score\n",
    "import catboost\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "for p in [np, pd, scipy, sklearn, lgb, catboost]:\n",
    "    print (p.__name__, p.__version__)\n",
    "    \n",
    "DATA_FOLDER = 'competitive-data-science-predict-future-sales'\n",
    "test_spec = pd.read_csv(os.path.join(DATA_FOLDER, 'test.csv'))\n",
    "\n",
    "index_cols=['item_id','shop_id','date_block_num']\n",
    "date_block_val = 33\n",
    "date_block_test = 35 # Dec 2015\n",
    "\n",
    "test2submission_mapping_generated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xCDUSYw8rWZX"
   },
   "outputs": [],
   "source": [
    "def write_predictions_by_array(array, filename):\n",
    "  df=pd.DataFrame(array)\n",
    "  df.columns=['item_cnt_month']\n",
    "  df.to_csv(os.path.join(DATA_FOLDER, filename), index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hF4l3wSvb020"
   },
   "outputs": [],
   "source": [
    "def clipped_rmse(gt, predicted,clip_min=0, clip_max=20):\n",
    "  target=np.minimum(np.maximum(gt,clip_min), clip_max)\n",
    "  return np.sqrt((target-predicted)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Feature set 2: text based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "all_data = pd.read_csv(os.path.join(DATA_FOLDER, 'feature_set_text.csv'))\n",
    "\n",
    "dates=all_data['date_block_num']\n",
    "\n",
    "y_train = all_data.loc[(dates>= date_block_val - 9) & (dates<= date_block_val - 2), 'target']\n",
    "y_trainval = all_data.loc[(dates>= date_block_test - 9) & (dates<= date_block_test - 2), 'target']\n",
    "y_val = all_data.loc[dates == date_block_val, 'target']\n",
    "y_test = all_data.loc[dates == date_block_test, 'target']\n",
    "\n",
    "to_drop_cols = ['target','date_block_num']\n",
    "\n",
    "X_train = all_data.loc[(dates>= date_block_val - 9) & (dates<= date_block_val - 2)].drop(to_drop_cols, axis=1)\n",
    "X_trainval = all_data.loc[(dates>= date_block_test - 9) & (dates<= date_block_test - 2)].drop(to_drop_cols, axis=1)\n",
    "X_val = all_data.loc[dates == date_block_val].drop(to_drop_cols, axis=1)\n",
    "X_test = all_data.loc[dates == date_block_test].drop(to_drop_cols, axis=1)\n",
    "\n",
    "shop_item2submissionid={}\n",
    "for idx, row in test_spec.iterrows():\n",
    "    shop_item2submissionid[str(row['shop_id'])+'_'+str(row['item_id'])] = row['ID']\n",
    "    \n",
    "test_data=all_data.loc[dates == date_block_test, ['shop_id','item_id']]    \n",
    "    \n",
    "testidx2submissionidx=np.zeros(test_data.shape[0], dtype=np.int32)\n",
    "for idx in range(test_data.shape[0]):\n",
    "    row =test_data.iloc[idx]\n",
    "    testidx2submissionidx[idx] = shop_item2submissionid[str(row['shop_id'])+'_'+str(row['item_id'])]\n",
    "    \n",
    " \n",
    "#invert the mapping\n",
    "submissionidx2testidx=np.zeros(test_data.shape[0], dtype=np.int32)\n",
    "for i in range(test_data.shape[0]):\n",
    "    submissionidx2testidx[testidx2submissionidx[i]]=i\n",
    "    \n",
    "del test_data\n",
    "gc.collect()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipped RMSE 0.46532662185032936\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#model=linear_model.RidgeCV(alphas=np.logspace(-3,13), fit_intercept=True, normalize=True)\n",
    "model=linear_model.Ridge(alpha=0.04, fit_intercept=True, normalize=True)\n",
    "model.fit(X_train.to_numpy(), y_train)\n",
    "pred_val = np.clip(model.predict(X_val.to_numpy()), 0, 20)\n",
    "#print('Validation R-squared for LightGBM is %f' % r2_score(y_val, pred_lgb_val))\n",
    "print('Clipped RMSE {}'.format(clipped_rmse(y_val, pred_val)))\n",
    "\n",
    "model.fit(X_trainval.to_numpy(), y_trainval)\n",
    "pred_test = np.clip(model.predict(X_test.to_numpy()), 0, 20)\n",
    "write_predictions_by_array(pred_test[submissionidx2testidx], 'submission-ridge-feature_set_text.csv')\n",
    "# LB 1.203418 and 1.189612\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_name_category_tfidf_bigram_256',\n",
       "       'target_category_tfidf_unigram_256_lag_6',\n",
       "       'target_category_frequent_256_lag_4', 'item_name_category_frequent_32',\n",
       "       'target_category_tfidf_unigram_256_within_shop_lag_12',\n",
       "       'target_category_tfidf_bigram_256_lag_5',\n",
       "       'target_category_tfidf_unigram_256_lag_2',\n",
       "       'target_category_frequent_256_within_shop_lag_4',\n",
       "       'item_name_category_frequent_256',\n",
       "       'item_name_category_tfidf_unigram_256',\n",
       "       'target_category_frequent_256_within_shop_lag_5',\n",
       "       'target_category_frequent_256_lag_5',\n",
       "       'item_name_category_tfidf_bigram_32',\n",
       "       'target_category_frequent_256_within_shop_lag_6',\n",
       "       'target_category_frequent_256_within_shop_lag_2',\n",
       "       'target_category_tfidf_unigram_256_lag_5',\n",
       "       'target_category_tfidf_bigram_256_within_shop_lag_12',\n",
       "       'target_category_frequent_256_lag_12',\n",
       "       'target_category_frequent_256_within_shop_lag_12',\n",
       "       'target_category_tfidf_unigram_256_within_shop_lag_2',\n",
       "       'target_category_frequent_256_lag_3',\n",
       "       'target_category_tfidf_bigram_256_within_shop_lag_2', 'shop_id',\n",
       "       'target_category_tfidf_bigram_256_within_shop_lag_5',\n",
       "       'target_category_tfidf_unigram_256_within_shop_lag_6',\n",
       "       'target_category_tfidf_bigram_256_within_shop_lag_3',\n",
       "       'target_category_tfidf_bigram_256_within_shop_lag_6',\n",
       "       'target_category_frequent_256_within_shop_lag_3',\n",
       "       'target_category_tfidf_bigram_256_lag_2', 'item_name_cyrillic_fraction',\n",
       "       'target_category_tfidf_bigram_256_lag_3',\n",
       "       'item_name_category_tfidf_unigram_32',\n",
       "       'target_category_tfidf_bigram_256_lag_6',\n",
       "       'target_category_tfidf_unigram_256_lag_12',\n",
       "       'target_category_tfidf_unigram_256_within_shop_lag_4',\n",
       "       'target_category_frequent_256_lag_6',\n",
       "       'target_category_tfidf_unigram_256_lag_4', 'item_id',\n",
       "       'target_category_tfidf_unigram_256_within_shop_lag_5',\n",
       "       'target_category_tfidf_unigram_256_lag_3',\n",
       "       'target_category_frequent_256_lag_2',\n",
       "       'target_category_tfidf_bigram_256_lag_4',\n",
       "       'target_category_tfidf_bigram_256_within_shop_lag_4',\n",
       "       'target_category_tfidf_unigram_256_within_shop_lag_3',\n",
       "       'target_category_tfidf_bigram_256_lag_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.2430756\ttotal: 4.19s\tremaining: 2h 26m 42s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-781fb7d0575f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#eval_dataset= Pool(X_val,y_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#reg.fit(X_train.to_numpy(), y_train, eval_set=eval_dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4478\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4479\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4480\u001b[0;31m                          save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   4481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1730\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1733\u001b[0m             )\n\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "reg=CatBoostRegressor(iterations=2100, depth=16, eta=lr,metric_period=20)\n",
    "#eval_dataset= Pool(X_val,y_val)\n",
    "#reg.fit(X_train.to_numpy(), y_train, eval_set=eval_dataset)\n",
    "reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.9938248\ttest: 5.3098607\tbest: 5.3098607 (0)\ttotal: 4.11s\tremaining: 6m 46s\n",
      "1:\tlearn: 2.8194187\ttest: 5.2276048\tbest: 5.2276048 (1)\ttotal: 8.23s\tremaining: 6m 43s\n",
      "2:\tlearn: 2.7197118\ttest: 5.1790292\tbest: 5.1790292 (2)\ttotal: 12.4s\tremaining: 6m 41s\n",
      "3:\tlearn: 2.6275895\ttest: 5.1653746\tbest: 5.1653746 (3)\ttotal: 16.5s\tremaining: 6m 36s\n",
      "4:\tlearn: 2.5644537\ttest: 5.1456011\tbest: 5.1456011 (4)\ttotal: 20.8s\tremaining: 6m 34s\n",
      "5:\tlearn: 2.4976971\ttest: 5.1274460\tbest: 5.1274460 (5)\ttotal: 25s\tremaining: 6m 31s\n",
      "6:\tlearn: 2.4389858\ttest: 5.1244156\tbest: 5.1244156 (6)\ttotal: 29.2s\tremaining: 6m 28s\n",
      "7:\tlearn: 2.3734834\ttest: 5.1118234\tbest: 5.1118234 (7)\ttotal: 33.5s\tremaining: 6m 24s\n",
      "8:\tlearn: 2.3301853\ttest: 4.9783693\tbest: 4.9783693 (8)\ttotal: 37.6s\tremaining: 6m 20s\n",
      "9:\tlearn: 2.3147680\ttest: 4.9776331\tbest: 4.9776331 (9)\ttotal: 41.9s\tremaining: 6m 16s\n",
      "10:\tlearn: 2.3032872\ttest: 4.9774073\tbest: 4.9774073 (10)\ttotal: 46s\tremaining: 6m 12s\n",
      "11:\tlearn: 2.2636778\ttest: 4.9768361\tbest: 4.9768361 (11)\ttotal: 50.3s\tremaining: 6m 8s\n",
      "12:\tlearn: 2.2388203\ttest: 4.9714697\tbest: 4.9714697 (12)\ttotal: 54.4s\tremaining: 6m 4s\n",
      "13:\tlearn: 2.2193127\ttest: 4.9703728\tbest: 4.9703728 (13)\ttotal: 58.5s\tremaining: 5m 59s\n",
      "14:\tlearn: 2.2047336\ttest: 4.9709232\tbest: 4.9703728 (13)\ttotal: 1m 2s\tremaining: 5m 55s\n",
      "15:\tlearn: 2.1878374\ttest: 4.9696705\tbest: 4.9696705 (15)\ttotal: 1m 6s\tremaining: 5m 50s\n",
      "16:\tlearn: 2.1712864\ttest: 4.9696555\tbest: 4.9696555 (16)\ttotal: 1m 10s\tremaining: 5m 46s\n",
      "17:\tlearn: 2.1318408\ttest: 4.9724295\tbest: 4.9696555 (16)\ttotal: 1m 15s\tremaining: 5m 42s\n",
      "18:\tlearn: 2.1195730\ttest: 4.9719506\tbest: 4.9696555 (16)\ttotal: 1m 19s\tremaining: 5m 37s\n",
      "19:\tlearn: 2.0790716\ttest: 4.9715210\tbest: 4.9696555 (16)\ttotal: 1m 23s\tremaining: 5m 33s\n",
      "20:\tlearn: 2.0685329\ttest: 4.9708603\tbest: 4.9696555 (16)\ttotal: 1m 27s\tremaining: 5m 29s\n",
      "21:\tlearn: 2.0603120\ttest: 4.9707661\tbest: 4.9696555 (16)\ttotal: 1m 31s\tremaining: 5m 24s\n",
      "22:\tlearn: 2.0448056\ttest: 4.9671498\tbest: 4.9671498 (22)\ttotal: 1m 35s\tremaining: 5m 20s\n",
      "23:\tlearn: 2.0359023\ttest: 4.9656247\tbest: 4.9656247 (23)\ttotal: 1m 39s\tremaining: 5m 16s\n",
      "24:\tlearn: 2.0268156\ttest: 4.9652013\tbest: 4.9652013 (24)\ttotal: 1m 43s\tremaining: 5m 11s\n",
      "25:\tlearn: 2.0170887\ttest: 4.9411947\tbest: 4.9411947 (25)\ttotal: 1m 48s\tremaining: 5m 7s\n",
      "26:\tlearn: 2.0056575\ttest: 4.9415974\tbest: 4.9411947 (25)\ttotal: 1m 52s\tremaining: 5m 3s\n",
      "27:\tlearn: 1.9912249\ttest: 4.9417862\tbest: 4.9411947 (25)\ttotal: 1m 56s\tremaining: 4m 59s\n",
      "28:\tlearn: 1.9824429\ttest: 4.9414271\tbest: 4.9411947 (25)\ttotal: 2m\tremaining: 4m 54s\n",
      "29:\tlearn: 1.9801293\ttest: 4.9413612\tbest: 4.9411947 (25)\ttotal: 2m 4s\tremaining: 4m 50s\n",
      "30:\tlearn: 1.9657350\ttest: 4.9394206\tbest: 4.9394206 (30)\ttotal: 2m 8s\tremaining: 4m 46s\n",
      "31:\tlearn: 1.9580373\ttest: 4.9394436\tbest: 4.9394206 (30)\ttotal: 2m 12s\tremaining: 4m 42s\n",
      "32:\tlearn: 1.9325185\ttest: 4.9070201\tbest: 4.9070201 (32)\ttotal: 2m 17s\tremaining: 4m 38s\n",
      "33:\tlearn: 1.9224648\ttest: 4.9069120\tbest: 4.9069120 (33)\ttotal: 2m 21s\tremaining: 4m 34s\n",
      "34:\tlearn: 1.9167896\ttest: 4.9081511\tbest: 4.9069120 (33)\ttotal: 2m 25s\tremaining: 4m 30s\n",
      "35:\tlearn: 1.9133267\ttest: 4.9087002\tbest: 4.9069120 (33)\ttotal: 2m 29s\tremaining: 4m 25s\n",
      "36:\tlearn: 1.9078237\ttest: 4.9075855\tbest: 4.9069120 (33)\ttotal: 2m 33s\tremaining: 4m 21s\n",
      "37:\tlearn: 1.8961275\ttest: 4.9044973\tbest: 4.9044973 (37)\ttotal: 2m 37s\tremaining: 4m 17s\n",
      "38:\tlearn: 1.8928901\ttest: 4.9044985\tbest: 4.9044973 (37)\ttotal: 2m 41s\tremaining: 4m 13s\n",
      "39:\tlearn: 1.8895851\ttest: 4.9053052\tbest: 4.9044973 (37)\ttotal: 2m 46s\tremaining: 4m 9s\n",
      "40:\tlearn: 1.8842802\ttest: 4.9056219\tbest: 4.9044973 (37)\ttotal: 2m 50s\tremaining: 4m 5s\n",
      "41:\tlearn: 1.8768745\ttest: 4.9060428\tbest: 4.9044973 (37)\ttotal: 2m 54s\tremaining: 4m\n",
      "42:\tlearn: 1.8743407\ttest: 4.9060540\tbest: 4.9044973 (37)\ttotal: 2m 58s\tremaining: 3m 56s\n",
      "43:\tlearn: 1.8689073\ttest: 4.9058698\tbest: 4.9044973 (37)\ttotal: 3m 2s\tremaining: 3m 52s\n",
      "44:\tlearn: 1.8647168\ttest: 4.9025887\tbest: 4.9025887 (44)\ttotal: 3m 6s\tremaining: 3m 48s\n",
      "45:\tlearn: 1.8614666\ttest: 4.9024831\tbest: 4.9024831 (45)\ttotal: 3m 10s\tremaining: 3m 44s\n",
      "46:\tlearn: 1.8421772\ttest: 4.8901413\tbest: 4.8901413 (46)\ttotal: 3m 14s\tremaining: 3m 39s\n",
      "47:\tlearn: 1.8159978\ttest: 4.8900083\tbest: 4.8900083 (47)\ttotal: 3m 19s\tremaining: 3m 35s\n",
      "48:\tlearn: 1.8026143\ttest: 4.8899740\tbest: 4.8899740 (48)\ttotal: 3m 23s\tremaining: 3m 31s\n",
      "49:\tlearn: 1.7914025\ttest: 4.8901783\tbest: 4.8899740 (48)\ttotal: 3m 27s\tremaining: 3m 27s\n",
      "50:\tlearn: 1.7855000\ttest: 4.8878356\tbest: 4.8878356 (50)\ttotal: 3m 31s\tremaining: 3m 23s\n",
      "51:\tlearn: 1.7751546\ttest: 4.8878349\tbest: 4.8878349 (51)\ttotal: 3m 35s\tremaining: 3m 18s\n",
      "52:\tlearn: 1.7664948\ttest: 4.8879285\tbest: 4.8878349 (51)\ttotal: 3m 39s\tremaining: 3m 14s\n",
      "53:\tlearn: 1.7590294\ttest: 4.8879869\tbest: 4.8878349 (51)\ttotal: 3m 43s\tremaining: 3m 10s\n",
      "54:\tlearn: 1.7527172\ttest: 4.8879957\tbest: 4.8878349 (51)\ttotal: 3m 47s\tremaining: 3m 6s\n",
      "55:\tlearn: 1.7470205\ttest: 4.8879940\tbest: 4.8878349 (51)\ttotal: 3m 51s\tremaining: 3m 2s\n",
      "56:\tlearn: 1.7421274\ttest: 4.8888546\tbest: 4.8878349 (51)\ttotal: 3m 56s\tremaining: 2m 58s\n",
      "57:\tlearn: 1.7379594\ttest: 4.8888616\tbest: 4.8878349 (51)\ttotal: 4m\tremaining: 2m 53s\n",
      "58:\tlearn: 1.7343938\ttest: 4.8888649\tbest: 4.8878349 (51)\ttotal: 4m 4s\tremaining: 2m 49s\n",
      "59:\tlearn: 1.7314111\ttest: 4.8889098\tbest: 4.8878349 (51)\ttotal: 4m 8s\tremaining: 2m 45s\n",
      "60:\tlearn: 1.7264846\ttest: 4.8890270\tbest: 4.8878349 (51)\ttotal: 4m 12s\tremaining: 2m 41s\n",
      "61:\tlearn: 1.7196094\ttest: 4.8878893\tbest: 4.8878349 (51)\ttotal: 4m 16s\tremaining: 2m 37s\n",
      "62:\tlearn: 1.7144474\ttest: 4.8866100\tbest: 4.8866100 (62)\ttotal: 4m 21s\tremaining: 2m 33s\n",
      "63:\tlearn: 1.7125995\ttest: 4.8866142\tbest: 4.8866100 (62)\ttotal: 4m 25s\tremaining: 2m 29s\n",
      "64:\tlearn: 1.7123142\ttest: 4.8866189\tbest: 4.8866100 (62)\ttotal: 4m 25s\tremaining: 2m 23s\n",
      "65:\tlearn: 1.7096100\ttest: 4.8861266\tbest: 4.8861266 (65)\ttotal: 4m 29s\tremaining: 2m 19s\n",
      "66:\tlearn: 1.7060254\ttest: 4.8844552\tbest: 4.8844552 (66)\ttotal: 4m 34s\tremaining: 2m 14s\n",
      "67:\tlearn: 1.7014690\ttest: 4.8843796\tbest: 4.8843796 (67)\ttotal: 4m 38s\tremaining: 2m 10s\n",
      "68:\tlearn: 1.6978380\ttest: 4.8835770\tbest: 4.8835770 (68)\ttotal: 4m 42s\tremaining: 2m 6s\n",
      "69:\tlearn: 1.6965446\ttest: 4.8835949\tbest: 4.8835770 (68)\ttotal: 4m 46s\tremaining: 2m 2s\n",
      "70:\tlearn: 1.6933379\ttest: 4.8832334\tbest: 4.8832334 (70)\ttotal: 4m 50s\tremaining: 1m 58s\n",
      "71:\tlearn: 1.6922028\ttest: 4.8832900\tbest: 4.8832334 (70)\ttotal: 4m 54s\tremaining: 1m 54s\n",
      "72:\tlearn: 1.6701373\ttest: 4.8837854\tbest: 4.8832334 (70)\ttotal: 4m 58s\tremaining: 1m 50s\n",
      "73:\tlearn: 1.6656177\ttest: 4.8838695\tbest: 4.8832334 (70)\ttotal: 5m 2s\tremaining: 1m 46s\n",
      "74:\tlearn: 1.6631135\ttest: 4.8819563\tbest: 4.8819563 (74)\ttotal: 5m 7s\tremaining: 1m 42s\n",
      "75:\tlearn: 1.6619689\ttest: 4.8819676\tbest: 4.8819563 (74)\ttotal: 5m 11s\tremaining: 1m 38s\n",
      "76:\tlearn: 1.6548332\ttest: 4.8813229\tbest: 4.8813229 (76)\ttotal: 5m 15s\tremaining: 1m 34s\n",
      "77:\tlearn: 1.6530641\ttest: 4.8821595\tbest: 4.8813229 (76)\ttotal: 5m 19s\tremaining: 1m 30s\n",
      "78:\tlearn: 1.6500448\ttest: 4.8820378\tbest: 4.8813229 (76)\ttotal: 5m 23s\tremaining: 1m 26s\n",
      "79:\tlearn: 1.6490239\ttest: 4.8820152\tbest: 4.8813229 (76)\ttotal: 5m 27s\tremaining: 1m 21s\n",
      "80:\tlearn: 1.6457663\ttest: 4.8831072\tbest: 4.8813229 (76)\ttotal: 5m 31s\tremaining: 1m 17s\n",
      "81:\tlearn: 1.6431144\ttest: 4.8836508\tbest: 4.8813229 (76)\ttotal: 5m 36s\tremaining: 1m 13s\n",
      "82:\tlearn: 1.6406289\ttest: 4.8835295\tbest: 4.8813229 (76)\ttotal: 5m 40s\tremaining: 1m 9s\n",
      "83:\tlearn: 1.6381309\ttest: 4.8822762\tbest: 4.8813229 (76)\ttotal: 5m 44s\tremaining: 1m 5s\n",
      "84:\tlearn: 1.6212073\ttest: 4.8826044\tbest: 4.8813229 (76)\ttotal: 5m 48s\tremaining: 1m 1s\n",
      "85:\tlearn: 1.6190433\ttest: 4.8826240\tbest: 4.8813229 (76)\ttotal: 5m 52s\tremaining: 57.4s\n",
      "86:\tlearn: 1.6054413\ttest: 4.8870159\tbest: 4.8813229 (76)\ttotal: 5m 56s\tremaining: 53.3s\n",
      "87:\tlearn: 1.6038255\ttest: 4.8869102\tbest: 4.8813229 (76)\ttotal: 6m 1s\tremaining: 49.2s\n",
      "88:\tlearn: 1.6014491\ttest: 4.8851388\tbest: 4.8813229 (76)\ttotal: 6m 5s\tremaining: 45.1s\n",
      "89:\tlearn: 1.5987936\ttest: 4.8848816\tbest: 4.8813229 (76)\ttotal: 6m 9s\tremaining: 41s\n",
      "90:\tlearn: 1.5982353\ttest: 4.8848974\tbest: 4.8813229 (76)\ttotal: 6m 13s\tremaining: 36.9s\n",
      "91:\tlearn: 1.5962958\ttest: 4.8846708\tbest: 4.8813229 (76)\ttotal: 6m 17s\tremaining: 32.8s\n",
      "92:\tlearn: 1.5882394\ttest: 4.8857321\tbest: 4.8813229 (76)\ttotal: 6m 21s\tremaining: 28.7s\n",
      "93:\tlearn: 1.5860713\ttest: 4.8855575\tbest: 4.8813229 (76)\ttotal: 6m 25s\tremaining: 24.6s\n",
      "94:\tlearn: 1.5835306\ttest: 4.8856169\tbest: 4.8813229 (76)\ttotal: 6m 30s\tremaining: 20.5s\n",
      "95:\tlearn: 1.5813166\ttest: 4.8855307\tbest: 4.8813229 (76)\ttotal: 6m 34s\tremaining: 16.4s\n",
      "96:\tlearn: 1.5790991\ttest: 4.8854747\tbest: 4.8813229 (76)\ttotal: 6m 38s\tremaining: 12.3s\n",
      "97:\tlearn: 1.5780591\ttest: 4.8853364\tbest: 4.8813229 (76)\ttotal: 6m 42s\tremaining: 8.21s\n",
      "98:\tlearn: 1.5771453\ttest: 4.8853140\tbest: 4.8813229 (76)\ttotal: 6m 46s\tremaining: 4.11s\n",
      "99:\tlearn: 1.5759293\ttest: 4.8851495\tbest: 4.8813229 (76)\ttotal: 6m 50s\tremaining: 0us\n",
      "\n",
      "bestTest = 4.881322866\n",
      "bestIteration = 76\n",
      "\n",
      "Shrink model to first 77 iterations.\n",
      "Clipped RMSE 0.39135611984817525\n"
     ]
    }
   ],
   "source": [
    "lr=0.3\n",
    "reg=CatBoostRegressor(iterations=100, depth=16, eta=lr,early_stopping_rounds=50)\n",
    "eval_dataset= Pool(X_val,y_val)\n",
    "#reg.fit(X_train.to_numpy(), y_train, eval_set=eval_dataset)\n",
    "reg.fit(X_train.to_numpy(), y_train, eval_set=eval_dataset)\n",
    "pred_val = np.clip(reg.predict(X_val.to_numpy()), 0, 20)\n",
    "    #print('Validation R-squared for LightGBM is %f' % r2_score(y_val, pred_lgb_val))\n",
    "print('Clipped RMSE {}'.format(clipped_rmse(y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.8032055\ttotal: 3.97s\tremaining: 4m 53s\n",
      "1:\tlearn: 3.5934791\ttotal: 8.06s\tremaining: 4m 54s\n",
      "2:\tlearn: 3.3624003\ttotal: 12.2s\tremaining: 4m 52s\n",
      "3:\tlearn: 3.2548566\ttotal: 16.3s\tremaining: 4m 49s\n",
      "4:\tlearn: 3.1810405\ttotal: 20.3s\tremaining: 4m 44s\n",
      "5:\tlearn: 3.1081750\ttotal: 24.5s\tremaining: 4m 42s\n",
      "6:\tlearn: 3.0140236\ttotal: 28.8s\tremaining: 4m 39s\n",
      "7:\tlearn: 2.9076039\ttotal: 32.9s\tremaining: 4m 35s\n",
      "8:\tlearn: 2.8283148\ttotal: 36.9s\tremaining: 4m 30s\n",
      "9:\tlearn: 2.7912424\ttotal: 41s\tremaining: 4m 26s\n",
      "10:\tlearn: 2.7416821\ttotal: 45.2s\tremaining: 4m 22s\n",
      "11:\tlearn: 2.7171035\ttotal: 49.3s\tremaining: 4m 18s\n",
      "12:\tlearn: 2.6968418\ttotal: 53.4s\tremaining: 4m 14s\n",
      "13:\tlearn: 2.6532292\ttotal: 57.5s\tremaining: 4m 10s\n",
      "14:\tlearn: 2.6021161\ttotal: 1m 1s\tremaining: 4m 6s\n",
      "15:\tlearn: 2.5572232\ttotal: 1m 5s\tremaining: 4m 1s\n",
      "16:\tlearn: 2.5168888\ttotal: 1m 9s\tremaining: 3m 57s\n",
      "17:\tlearn: 2.4807065\ttotal: 1m 13s\tremaining: 3m 53s\n",
      "18:\tlearn: 2.4585676\ttotal: 1m 17s\tremaining: 3m 49s\n",
      "19:\tlearn: 2.4393804\ttotal: 1m 21s\tremaining: 3m 44s\n",
      "20:\tlearn: 2.3933465\ttotal: 1m 25s\tremaining: 3m 40s\n",
      "21:\tlearn: 2.3765165\ttotal: 1m 29s\tremaining: 3m 36s\n",
      "22:\tlearn: 2.3598871\ttotal: 1m 33s\tremaining: 3m 32s\n",
      "23:\tlearn: 2.3384363\ttotal: 1m 38s\tremaining: 3m 28s\n",
      "24:\tlearn: 2.3271232\ttotal: 1m 42s\tremaining: 3m 24s\n",
      "25:\tlearn: 2.3143578\ttotal: 1m 46s\tremaining: 3m 20s\n",
      "26:\tlearn: 2.3001326\ttotal: 1m 50s\tremaining: 3m 16s\n",
      "27:\tlearn: 2.2816969\ttotal: 1m 54s\tremaining: 3m 12s\n",
      "28:\tlearn: 2.2641304\ttotal: 1m 58s\tremaining: 3m 8s\n",
      "29:\tlearn: 2.2592417\ttotal: 2m 2s\tremaining: 3m 4s\n",
      "30:\tlearn: 2.2523762\ttotal: 2m 6s\tremaining: 3m\n",
      "31:\tlearn: 2.2455716\ttotal: 2m 10s\tremaining: 2m 55s\n",
      "32:\tlearn: 2.2368539\ttotal: 2m 15s\tremaining: 2m 51s\n",
      "33:\tlearn: 2.2341566\ttotal: 2m 19s\tremaining: 2m 47s\n",
      "34:\tlearn: 2.2264766\ttotal: 2m 23s\tremaining: 2m 43s\n",
      "35:\tlearn: 2.2181896\ttotal: 2m 27s\tremaining: 2m 39s\n",
      "36:\tlearn: 2.2076055\ttotal: 2m 31s\tremaining: 2m 35s\n",
      "37:\tlearn: 2.2056125\ttotal: 2m 35s\tremaining: 2m 31s\n",
      "38:\tlearn: 2.1956326\ttotal: 2m 39s\tremaining: 2m 27s\n",
      "39:\tlearn: 2.1899312\ttotal: 2m 43s\tremaining: 2m 23s\n",
      "40:\tlearn: 2.1838144\ttotal: 2m 48s\tremaining: 2m 19s\n",
      "41:\tlearn: 2.1798593\ttotal: 2m 52s\tremaining: 2m 15s\n",
      "42:\tlearn: 2.1752397\ttotal: 2m 56s\tremaining: 2m 11s\n",
      "43:\tlearn: 2.1481650\ttotal: 3m\tremaining: 2m 7s\n",
      "44:\tlearn: 2.1455388\ttotal: 3m 5s\tremaining: 2m 3s\n",
      "45:\tlearn: 2.1430709\ttotal: 3m 9s\tremaining: 1m 59s\n",
      "46:\tlearn: 2.1305016\ttotal: 3m 13s\tremaining: 1m 55s\n",
      "47:\tlearn: 2.1161067\ttotal: 3m 17s\tremaining: 1m 50s\n",
      "48:\tlearn: 2.1023565\ttotal: 3m 21s\tremaining: 1m 46s\n",
      "49:\tlearn: 2.0956004\ttotal: 3m 25s\tremaining: 1m 42s\n",
      "50:\tlearn: 2.0945004\ttotal: 3m 30s\tremaining: 1m 38s\n",
      "51:\tlearn: 2.0861387\ttotal: 3m 34s\tremaining: 1m 34s\n",
      "52:\tlearn: 2.0826940\ttotal: 3m 38s\tremaining: 1m 30s\n",
      "53:\tlearn: 2.0787901\ttotal: 3m 42s\tremaining: 1m 26s\n",
      "54:\tlearn: 2.0675442\ttotal: 3m 47s\tremaining: 1m 22s\n",
      "55:\tlearn: 2.0577843\ttotal: 3m 51s\tremaining: 1m 18s\n",
      "56:\tlearn: 2.0556863\ttotal: 3m 55s\tremaining: 1m 14s\n",
      "57:\tlearn: 2.0522251\ttotal: 3m 59s\tremaining: 1m 10s\n",
      "58:\tlearn: 2.0488483\ttotal: 4m 3s\tremaining: 1m 6s\n",
      "59:\tlearn: 2.0443898\ttotal: 4m 7s\tremaining: 1m 1s\n",
      "60:\tlearn: 2.0419252\ttotal: 4m 12s\tremaining: 57.9s\n",
      "61:\tlearn: 2.0381273\ttotal: 4m 16s\tremaining: 53.7s\n",
      "62:\tlearn: 2.0348357\ttotal: 4m 20s\tremaining: 49.6s\n",
      "63:\tlearn: 2.0284398\ttotal: 4m 24s\tremaining: 45.4s\n",
      "64:\tlearn: 2.0066152\ttotal: 4m 28s\tremaining: 41.4s\n",
      "65:\tlearn: 1.9988054\ttotal: 4m 32s\tremaining: 37.2s\n",
      "66:\tlearn: 1.9929904\ttotal: 4m 37s\tremaining: 33.1s\n",
      "67:\tlearn: 1.9900535\ttotal: 4m 41s\tremaining: 28.9s\n",
      "68:\tlearn: 1.9853907\ttotal: 4m 45s\tremaining: 24.8s\n",
      "69:\tlearn: 1.9787662\ttotal: 4m 49s\tremaining: 20.7s\n",
      "70:\tlearn: 1.9749708\ttotal: 4m 53s\tremaining: 16.6s\n",
      "71:\tlearn: 1.9739461\ttotal: 4m 58s\tremaining: 12.4s\n",
      "72:\tlearn: 1.9722417\ttotal: 5m 2s\tremaining: 8.28s\n",
      "73:\tlearn: 1.9562141\ttotal: 5m 6s\tremaining: 4.14s\n",
      "74:\tlearn: 1.9507433\ttotal: 5m 10s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "reg=CatBoostRegressor(iterations=75, depth=16, eta=0.3)\n",
    "reg.fit(X_trainval.to_numpy(), y_trainval)\n",
    "pred_test = np.clip(reg.predict(X_test.to_numpy()), 0, 20)\n",
    "write_predictions_by_array(pred_test[submissionidx2testidx], 'submission-catboost-feature_set_text-lr0.01.csv')\n",
    "# LB score 1.121911 and 1.11979"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature set 3: lags within shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "all_data = pd.read_csv(os.path.join(DATA_FOLDER, 'feature_set_within.csv'))\n",
    "\n",
    "dates=all_data['date_block_num']\n",
    "\n",
    "y_train = all_data.loc[(dates>= date_block_val - 9) & (dates<= date_block_val - 2), 'target']\n",
    "y_trainval = all_data.loc[(dates>= date_block_test - 9) & (dates<= date_block_test - 2), 'target']\n",
    "y_val = all_data.loc[dates == date_block_val, 'target']\n",
    "y_test = all_data.loc[dates == date_block_test, 'target']\n",
    "\n",
    "to_drop_cols = ['target','date_block_num']\n",
    "\n",
    "X_train = all_data.loc[(dates>= date_block_val - 9) & (dates<= date_block_val - 2)].drop(to_drop_cols, axis=1)\n",
    "X_trainval = all_data.loc[(dates>= date_block_test - 9) & (dates<= date_block_test - 2)].drop(to_drop_cols, axis=1)\n",
    "X_val = all_data.loc[dates == date_block_val].drop(to_drop_cols, axis=1)\n",
    "X_test = all_data.loc[dates == date_block_test].drop(to_drop_cols, axis=1)\n",
    "\n",
    "shop_item2submissionid={}\n",
    "for idx, row in test_spec.iterrows():\n",
    "    shop_item2submissionid[str(row['shop_id'])+'_'+str(row['item_id'])] = row['ID']\n",
    "    \n",
    "test_data=all_data.loc[dates == date_block_test, ['shop_id','item_id']]    \n",
    "    \n",
    "testidx2submissionidx=np.zeros(test_data.shape[0], dtype=np.int32)\n",
    "for idx in range(test_data.shape[0]):\n",
    "    row =test_data.iloc[idx]\n",
    "    testidx2submissionidx[idx] = shop_item2submissionid[str(row['shop_id'])+'_'+str(row['item_id'])]\n",
    "    \n",
    " \n",
    "#invert the mapping\n",
    "submissionidx2testidx=np.zeros(test_data.shape[0], dtype=np.int32)\n",
    "for i in range(test_data.shape[0]):\n",
    "    submissionidx2testidx[testidx2submissionidx[i]]=i\n",
    "    \n",
    "del test_data\n",
    "gc.collect()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#model=linear_model.RidgeCV(alphas=np.logspace(-3,13), fit_intercept=False)\n",
    "model=linear_model.Ridge(alpha=3e7, fit_intercept=False)\n",
    "model.fit(X_train.to_numpy(), y_train)\n",
    "pred_val = np.clip(model.predict(X_val.to_numpy()), 0, 20)\n",
    "#print('Validation R-squared for LightGBM is %f' % r2_score(y_val, pred_lgb_val))\n",
    "print('Clipped RMSE {}'.format(clipped_rmse(y_val, pred_val)))\n",
    "\n",
    "model.fit(X_trainval.to_numpy(), y_trainval)\n",
    "pred_test = np.clip(model.predict(X_test.to_numpy()), 0, 20)\n",
    "write_predictions_by_array(pred_test[submissionidx2testidx], 'submission-ridge-feature_set_within.csv')\n",
    "# LB 1.215079 and 1.202396\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.9968440\ttest: 5.3387101\tbest: 5.3387101 (0)\ttotal: 3.92s\tremaining: 6m 27s\n",
      "1:\tlearn: 2.8941772\ttest: 5.3108525\tbest: 5.3108525 (1)\ttotal: 7.86s\tremaining: 6m 25s\n",
      "2:\tlearn: 2.7389500\ttest: 5.2505995\tbest: 5.2505995 (2)\ttotal: 11.8s\tremaining: 6m 20s\n",
      "3:\tlearn: 2.6352402\ttest: 5.1358947\tbest: 5.1358947 (3)\ttotal: 15.6s\tremaining: 6m 15s\n",
      "4:\tlearn: 2.6038726\ttest: 5.1348162\tbest: 5.1348162 (4)\ttotal: 19.5s\tremaining: 6m 10s\n",
      "5:\tlearn: 2.5414224\ttest: 5.1220145\tbest: 5.1220145 (5)\ttotal: 23.3s\tremaining: 6m 5s\n",
      "6:\tlearn: 2.4635186\ttest: 5.0986699\tbest: 5.0986699 (6)\ttotal: 27.2s\tremaining: 6m 1s\n",
      "7:\tlearn: 2.4458983\ttest: 5.0984144\tbest: 5.0984144 (7)\ttotal: 31s\tremaining: 5m 56s\n",
      "8:\tlearn: 2.4226695\ttest: 5.0516756\tbest: 5.0516756 (8)\ttotal: 34.9s\tremaining: 5m 52s\n",
      "9:\tlearn: 2.4077369\ttest: 5.0512090\tbest: 5.0512090 (9)\ttotal: 38.7s\tremaining: 5m 48s\n",
      "10:\tlearn: 2.3787095\ttest: 5.0424099\tbest: 5.0424099 (10)\ttotal: 42.6s\tremaining: 5m 44s\n",
      "11:\tlearn: 2.3660573\ttest: 5.0422021\tbest: 5.0422021 (11)\ttotal: 46.4s\tremaining: 5m 40s\n",
      "12:\tlearn: 2.3342727\ttest: 5.0341989\tbest: 5.0341989 (12)\ttotal: 50.3s\tremaining: 5m 36s\n",
      "13:\tlearn: 2.3022805\ttest: 5.0130133\tbest: 5.0130133 (13)\ttotal: 54.1s\tremaining: 5m 32s\n",
      "14:\tlearn: 2.2768104\ttest: 5.0044953\tbest: 5.0044953 (14)\ttotal: 58.1s\tremaining: 5m 29s\n",
      "15:\tlearn: 2.2669167\ttest: 5.0012677\tbest: 5.0012677 (15)\ttotal: 1m 1s\tremaining: 5m 25s\n",
      "16:\tlearn: 2.2529894\ttest: 5.0018101\tbest: 5.0012677 (15)\ttotal: 1m 5s\tremaining: 5m 21s\n",
      "17:\tlearn: 2.2446247\ttest: 4.9800304\tbest: 4.9800304 (17)\ttotal: 1m 9s\tremaining: 5m 17s\n",
      "18:\tlearn: 2.2373394\ttest: 4.9811383\tbest: 4.9800304 (17)\ttotal: 1m 13s\tremaining: 5m 13s\n",
      "19:\tlearn: 2.2281759\ttest: 4.9795289\tbest: 4.9795289 (19)\ttotal: 1m 17s\tremaining: 5m 9s\n",
      "20:\tlearn: 2.2109223\ttest: 4.9752883\tbest: 4.9752883 (20)\ttotal: 1m 21s\tremaining: 5m 5s\n",
      "21:\tlearn: 2.2011075\ttest: 4.9746785\tbest: 4.9746785 (21)\ttotal: 1m 25s\tremaining: 5m 1s\n",
      "22:\tlearn: 2.1900935\ttest: 4.9732720\tbest: 4.9732720 (22)\ttotal: 1m 28s\tremaining: 4m 57s\n",
      "23:\tlearn: 2.1846210\ttest: 4.9741135\tbest: 4.9732720 (22)\ttotal: 1m 32s\tremaining: 4m 54s\n",
      "24:\tlearn: 2.1765834\ttest: 4.9697005\tbest: 4.9697005 (24)\ttotal: 1m 36s\tremaining: 4m 50s\n",
      "25:\tlearn: 2.1662540\ttest: 4.9688117\tbest: 4.9688117 (25)\ttotal: 1m 40s\tremaining: 4m 46s\n",
      "26:\tlearn: 2.1606334\ttest: 4.9669085\tbest: 4.9669085 (26)\ttotal: 1m 44s\tremaining: 4m 42s\n",
      "27:\tlearn: 2.1539344\ttest: 4.9667279\tbest: 4.9667279 (27)\ttotal: 1m 48s\tremaining: 4m 38s\n",
      "28:\tlearn: 2.1466012\ttest: 4.9568547\tbest: 4.9568547 (28)\ttotal: 1m 52s\tremaining: 4m 35s\n",
      "29:\tlearn: 2.1423157\ttest: 4.9440551\tbest: 4.9440551 (29)\ttotal: 1m 56s\tremaining: 4m 31s\n",
      "30:\tlearn: 2.1327399\ttest: 4.9428663\tbest: 4.9428663 (30)\ttotal: 2m\tremaining: 4m 27s\n",
      "31:\tlearn: 2.1242444\ttest: 4.9437052\tbest: 4.9428663 (30)\ttotal: 2m 4s\tremaining: 4m 24s\n",
      "32:\tlearn: 2.1223380\ttest: 4.9436985\tbest: 4.9428663 (30)\ttotal: 2m 8s\tremaining: 4m 20s\n",
      "33:\tlearn: 2.1153359\ttest: 4.9413830\tbest: 4.9413830 (33)\ttotal: 2m 12s\tremaining: 4m 16s\n",
      "34:\tlearn: 2.1123500\ttest: 4.9414023\tbest: 4.9413830 (33)\ttotal: 2m 15s\tremaining: 4m 12s\n",
      "35:\tlearn: 2.1083720\ttest: 4.9412543\tbest: 4.9412543 (35)\ttotal: 2m 19s\tremaining: 4m 8s\n",
      "36:\tlearn: 2.1066310\ttest: 4.9409695\tbest: 4.9409695 (36)\ttotal: 2m 23s\tremaining: 4m 4s\n",
      "37:\tlearn: 2.0994129\ttest: 4.9289827\tbest: 4.9289827 (37)\ttotal: 2m 28s\tremaining: 4m 1s\n",
      "38:\tlearn: 2.0971022\ttest: 4.9287164\tbest: 4.9287164 (38)\ttotal: 2m 32s\tremaining: 3m 57s\n",
      "39:\tlearn: 2.0915223\ttest: 4.9258760\tbest: 4.9258760 (39)\ttotal: 2m 36s\tremaining: 3m 54s\n",
      "40:\tlearn: 2.0891226\ttest: 4.9264599\tbest: 4.9258760 (39)\ttotal: 2m 40s\tremaining: 3m 50s\n",
      "41:\tlearn: 2.0865876\ttest: 4.9267266\tbest: 4.9258760 (39)\ttotal: 2m 44s\tremaining: 3m 46s\n",
      "42:\tlearn: 2.0843126\ttest: 4.9296513\tbest: 4.9258760 (39)\ttotal: 2m 48s\tremaining: 3m 42s\n",
      "43:\tlearn: 2.0833177\ttest: 4.9295146\tbest: 4.9258760 (39)\ttotal: 2m 51s\tremaining: 3m 38s\n",
      "44:\tlearn: 2.0813751\ttest: 4.9281735\tbest: 4.9258760 (39)\ttotal: 2m 55s\tremaining: 3m 34s\n",
      "45:\tlearn: 2.0785829\ttest: 4.9279330\tbest: 4.9258760 (39)\ttotal: 2m 59s\tremaining: 3m 30s\n",
      "46:\tlearn: 2.0757850\ttest: 4.9263858\tbest: 4.9258760 (39)\ttotal: 3m 3s\tremaining: 3m 27s\n",
      "47:\tlearn: 2.0741229\ttest: 4.9263704\tbest: 4.9258760 (39)\ttotal: 3m 7s\tremaining: 3m 23s\n",
      "48:\tlearn: 2.0711835\ttest: 4.9240538\tbest: 4.9240538 (48)\ttotal: 3m 11s\tremaining: 3m 19s\n",
      "49:\tlearn: 2.0699532\ttest: 4.9240692\tbest: 4.9240538 (48)\ttotal: 3m 15s\tremaining: 3m 15s\n",
      "50:\tlearn: 2.0687511\ttest: 4.9197983\tbest: 4.9197983 (50)\ttotal: 3m 18s\tremaining: 3m 11s\n",
      "51:\tlearn: 2.0657131\ttest: 4.9194838\tbest: 4.9194838 (51)\ttotal: 3m 22s\tremaining: 3m 7s\n",
      "52:\tlearn: 2.0647621\ttest: 4.9194950\tbest: 4.9194838 (51)\ttotal: 3m 26s\tremaining: 3m 3s\n",
      "53:\tlearn: 2.0635246\ttest: 4.9192870\tbest: 4.9192870 (53)\ttotal: 3m 30s\tremaining: 2m 59s\n",
      "54:\tlearn: 2.0614855\ttest: 4.9124557\tbest: 4.9124557 (54)\ttotal: 3m 34s\tremaining: 2m 55s\n",
      "55:\tlearn: 2.0605725\ttest: 4.9124297\tbest: 4.9124297 (55)\ttotal: 3m 38s\tremaining: 2m 51s\n",
      "56:\tlearn: 2.0586169\ttest: 4.9121837\tbest: 4.9121837 (56)\ttotal: 3m 42s\tremaining: 2m 47s\n",
      "57:\tlearn: 2.0571497\ttest: 4.9121260\tbest: 4.9121260 (57)\ttotal: 3m 46s\tremaining: 2m 43s\n",
      "58:\tlearn: 2.0551282\ttest: 4.9117889\tbest: 4.9117889 (58)\ttotal: 3m 50s\tremaining: 2m 40s\n",
      "59:\tlearn: 2.0530322\ttest: 4.9118125\tbest: 4.9117889 (58)\ttotal: 3m 54s\tremaining: 2m 36s\n",
      "60:\tlearn: 2.0505252\ttest: 4.9080872\tbest: 4.9080872 (60)\ttotal: 3m 58s\tremaining: 2m 32s\n",
      "61:\tlearn: 2.0492904\ttest: 4.9063655\tbest: 4.9063655 (61)\ttotal: 4m 2s\tremaining: 2m 28s\n",
      "62:\tlearn: 2.0464599\ttest: 4.9057437\tbest: 4.9057437 (62)\ttotal: 4m 6s\tremaining: 2m 24s\n",
      "63:\tlearn: 2.0452435\ttest: 4.9056327\tbest: 4.9056327 (63)\ttotal: 4m 9s\tremaining: 2m 20s\n",
      "64:\tlearn: 2.0438642\ttest: 4.9055257\tbest: 4.9055257 (64)\ttotal: 4m 13s\tremaining: 2m 16s\n",
      "65:\tlearn: 2.0428896\ttest: 4.9055278\tbest: 4.9055257 (64)\ttotal: 4m 17s\tremaining: 2m 12s\n",
      "66:\tlearn: 2.0401842\ttest: 4.9057993\tbest: 4.9055257 (64)\ttotal: 4m 21s\tremaining: 2m 8s\n",
      "67:\tlearn: 2.0374974\ttest: 4.9060288\tbest: 4.9055257 (64)\ttotal: 4m 25s\tremaining: 2m 4s\n",
      "68:\tlearn: 2.0359147\ttest: 4.9057792\tbest: 4.9055257 (64)\ttotal: 4m 29s\tremaining: 2m 1s\n",
      "69:\tlearn: 2.0346775\ttest: 4.9059570\tbest: 4.9055257 (64)\ttotal: 4m 33s\tremaining: 1m 57s\n",
      "70:\tlearn: 2.0331792\ttest: 4.9054475\tbest: 4.9054475 (70)\ttotal: 4m 37s\tremaining: 1m 53s\n",
      "71:\tlearn: 2.0323608\ttest: 4.9039194\tbest: 4.9039194 (71)\ttotal: 4m 40s\tremaining: 1m 49s\n",
      "72:\tlearn: 2.0316610\ttest: 4.9027594\tbest: 4.9027594 (72)\ttotal: 4m 44s\tremaining: 1m 45s\n",
      "73:\tlearn: 2.0305321\ttest: 4.9027751\tbest: 4.9027594 (72)\ttotal: 4m 48s\tremaining: 1m 41s\n",
      "74:\tlearn: 2.0290768\ttest: 4.9026644\tbest: 4.9026644 (74)\ttotal: 4m 52s\tremaining: 1m 37s\n",
      "75:\tlearn: 2.0283006\ttest: 4.9026504\tbest: 4.9026504 (75)\ttotal: 4m 56s\tremaining: 1m 33s\n",
      "76:\tlearn: 2.0269569\ttest: 4.9012439\tbest: 4.9012439 (76)\ttotal: 5m\tremaining: 1m 29s\n",
      "77:\tlearn: 2.0254483\ttest: 4.8994631\tbest: 4.8994631 (77)\ttotal: 5m 4s\tremaining: 1m 25s\n",
      "78:\tlearn: 2.0240950\ttest: 4.8995067\tbest: 4.8994631 (77)\ttotal: 5m 8s\tremaining: 1m 21s\n",
      "79:\tlearn: 2.0233673\ttest: 4.8996459\tbest: 4.8994631 (77)\ttotal: 5m 12s\tremaining: 1m 18s\n",
      "80:\tlearn: 2.0218057\ttest: 4.8995657\tbest: 4.8994631 (77)\ttotal: 5m 16s\tremaining: 1m 14s\n",
      "81:\tlearn: 2.0208162\ttest: 4.8994385\tbest: 4.8994385 (81)\ttotal: 5m 19s\tremaining: 1m 10s\n",
      "82:\tlearn: 2.0204082\ttest: 4.8988362\tbest: 4.8988362 (82)\ttotal: 5m 23s\tremaining: 1m 6s\n",
      "83:\tlearn: 2.0194807\ttest: 4.8988585\tbest: 4.8988362 (82)\ttotal: 5m 27s\tremaining: 1m 2s\n",
      "84:\tlearn: 2.0181733\ttest: 4.8988370\tbest: 4.8988362 (82)\ttotal: 5m 31s\tremaining: 58.5s\n",
      "85:\tlearn: 2.0172246\ttest: 4.8988024\tbest: 4.8988024 (85)\ttotal: 5m 35s\tremaining: 54.6s\n",
      "86:\tlearn: 2.0159999\ttest: 4.8989910\tbest: 4.8988024 (85)\ttotal: 5m 39s\tremaining: 50.7s\n",
      "87:\tlearn: 2.0149667\ttest: 4.8990347\tbest: 4.8988024 (85)\ttotal: 5m 43s\tremaining: 46.8s\n",
      "88:\tlearn: 2.0144741\ttest: 4.8989391\tbest: 4.8988024 (85)\ttotal: 5m 47s\tremaining: 42.9s\n",
      "89:\tlearn: 2.0138916\ttest: 4.8988249\tbest: 4.8988024 (85)\ttotal: 5m 51s\tremaining: 39s\n",
      "90:\tlearn: 2.0093310\ttest: 4.9004407\tbest: 4.8988024 (85)\ttotal: 5m 55s\tremaining: 35.1s\n",
      "91:\tlearn: 2.0079091\ttest: 4.9004152\tbest: 4.8988024 (85)\ttotal: 5m 59s\tremaining: 31.2s\n",
      "92:\tlearn: 2.0071256\ttest: 4.9002910\tbest: 4.8988024 (85)\ttotal: 6m 2s\tremaining: 27.3s\n",
      "93:\tlearn: 2.0063759\ttest: 4.9003052\tbest: 4.8988024 (85)\ttotal: 6m 6s\tremaining: 23.4s\n",
      "94:\tlearn: 2.0058380\ttest: 4.9003393\tbest: 4.8988024 (85)\ttotal: 6m 10s\tremaining: 19.5s\n",
      "95:\tlearn: 2.0050333\ttest: 4.9004472\tbest: 4.8988024 (85)\ttotal: 6m 14s\tremaining: 15.6s\n",
      "96:\tlearn: 2.0040299\ttest: 4.9005818\tbest: 4.8988024 (85)\ttotal: 6m 18s\tremaining: 11.7s\n",
      "97:\tlearn: 2.0036786\ttest: 4.9005681\tbest: 4.8988024 (85)\ttotal: 6m 22s\tremaining: 7.81s\n",
      "98:\tlearn: 2.0026466\ttest: 4.8999968\tbest: 4.8988024 (85)\ttotal: 6m 26s\tremaining: 3.9s\n",
      "99:\tlearn: 2.0024158\ttest: 4.9000575\tbest: 4.8988024 (85)\ttotal: 6m 30s\tremaining: 0us\n",
      "\n",
      "bestTest = 4.898802372\n",
      "bestIteration = 85\n",
      "\n",
      "Shrink model to first 86 iterations.\n",
      "Clipped RMSE 0.3965747233941849\n"
     ]
    }
   ],
   "source": [
    "lr=0.3\n",
    "reg=CatBoostRegressor(iterations=100, depth=16, eta=lr,early_stopping_rounds=50)\n",
    "eval_dataset= Pool(X_val,y_val)\n",
    "#reg.fit(X_train.to_numpy(), y_train, eval_set=eval_dataset)\n",
    "reg.fit(X_train.to_numpy(), y_train, eval_set=eval_dataset)\n",
    "pred_val = np.clip(reg.predict(X_val.to_numpy()), 0, 20)\n",
    "    #print('Validation R-squared for LightGBM is %f' % r2_score(y_val, pred_lgb_val))\n",
    "print('Clipped RMSE {}'.format(clipped_rmse(y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3.8506874\ttotal: 3.83s\tremaining: 5m 40s\n",
      "1:\tlearn: 3.6068670\ttotal: 7.67s\tremaining: 5m 37s\n",
      "2:\tlearn: 3.4484906\ttotal: 11.5s\tremaining: 5m 34s\n",
      "3:\tlearn: 3.3430640\ttotal: 15.4s\tremaining: 5m 31s\n",
      "4:\tlearn: 3.2802332\ttotal: 19.3s\tremaining: 5m 27s\n",
      "5:\tlearn: 3.2383940\ttotal: 23s\tremaining: 5m 22s\n",
      "6:\tlearn: 3.1713835\ttotal: 26.9s\tremaining: 5m 19s\n",
      "7:\tlearn: 3.1461231\ttotal: 30.8s\tremaining: 5m 16s\n",
      "8:\tlearn: 3.1309449\ttotal: 34.7s\tremaining: 5m 12s\n",
      "9:\tlearn: 3.1045289\ttotal: 38.6s\tremaining: 5m 8s\n",
      "10:\tlearn: 3.0654204\ttotal: 42.4s\tremaining: 5m 4s\n",
      "11:\tlearn: 3.0368718\ttotal: 46.3s\tremaining: 5m\n",
      "12:\tlearn: 3.0229326\ttotal: 50.4s\tremaining: 4m 58s\n",
      "13:\tlearn: 3.0067326\ttotal: 54.5s\tremaining: 4m 55s\n",
      "14:\tlearn: 2.9953285\ttotal: 58.3s\tremaining: 4m 51s\n",
      "15:\tlearn: 2.9910267\ttotal: 1m 2s\tremaining: 4m 47s\n",
      "16:\tlearn: 2.9795751\ttotal: 1m 6s\tremaining: 4m 43s\n",
      "17:\tlearn: 2.9759359\ttotal: 1m 9s\tremaining: 4m 39s\n",
      "18:\tlearn: 2.9733146\ttotal: 1m 13s\tremaining: 4m 35s\n",
      "19:\tlearn: 2.9710599\ttotal: 1m 17s\tremaining: 4m 30s\n",
      "20:\tlearn: 2.9650853\ttotal: 1m 21s\tremaining: 4m 27s\n",
      "21:\tlearn: 2.9592968\ttotal: 1m 25s\tremaining: 4m 22s\n",
      "22:\tlearn: 2.9488416\ttotal: 1m 28s\tremaining: 4m 18s\n",
      "23:\tlearn: 2.9467905\ttotal: 1m 32s\tremaining: 4m 14s\n",
      "24:\tlearn: 2.9426556\ttotal: 1m 36s\tremaining: 4m 10s\n",
      "25:\tlearn: 2.9361958\ttotal: 1m 40s\tremaining: 4m 6s\n",
      "26:\tlearn: 2.9309192\ttotal: 1m 44s\tremaining: 4m 2s\n",
      "27:\tlearn: 2.9287406\ttotal: 1m 47s\tremaining: 3m 58s\n",
      "28:\tlearn: 2.9247396\ttotal: 1m 51s\tremaining: 3m 54s\n",
      "29:\tlearn: 2.9195799\ttotal: 1m 55s\tremaining: 3m 50s\n",
      "30:\tlearn: 2.9175044\ttotal: 1m 59s\tremaining: 3m 47s\n",
      "31:\tlearn: 2.9145348\ttotal: 2m 3s\tremaining: 3m 43s\n",
      "32:\tlearn: 2.9059127\ttotal: 2m 7s\tremaining: 3m 39s\n",
      "33:\tlearn: 2.9043953\ttotal: 2m 10s\tremaining: 3m 35s\n",
      "34:\tlearn: 2.9013900\ttotal: 2m 14s\tremaining: 3m 31s\n",
      "35:\tlearn: 2.9003802\ttotal: 2m 18s\tremaining: 3m 28s\n",
      "36:\tlearn: 2.8988072\ttotal: 2m 22s\tremaining: 3m 24s\n",
      "37:\tlearn: 2.8972535\ttotal: 2m 26s\tremaining: 3m 20s\n",
      "38:\tlearn: 2.8954466\ttotal: 2m 30s\tremaining: 3m 16s\n",
      "39:\tlearn: 2.8904350\ttotal: 2m 34s\tremaining: 3m 13s\n",
      "40:\tlearn: 2.8886050\ttotal: 2m 38s\tremaining: 3m 9s\n",
      "41:\tlearn: 2.8855820\ttotal: 2m 42s\tremaining: 3m 5s\n",
      "42:\tlearn: 2.8847028\ttotal: 2m 45s\tremaining: 3m 1s\n",
      "43:\tlearn: 2.8791485\ttotal: 2m 49s\tremaining: 2m 57s\n",
      "44:\tlearn: 2.8752042\ttotal: 2m 53s\tremaining: 2m 53s\n",
      "45:\tlearn: 2.8740107\ttotal: 2m 57s\tremaining: 2m 49s\n",
      "46:\tlearn: 2.8727561\ttotal: 3m 1s\tremaining: 2m 45s\n",
      "47:\tlearn: 2.8716282\ttotal: 3m 5s\tremaining: 2m 42s\n",
      "48:\tlearn: 2.8708789\ttotal: 3m 8s\tremaining: 2m 38s\n",
      "49:\tlearn: 2.8696053\ttotal: 3m 12s\tremaining: 2m 34s\n",
      "50:\tlearn: 2.8682519\ttotal: 3m 16s\tremaining: 2m 30s\n",
      "51:\tlearn: 2.8673564\ttotal: 3m 20s\tremaining: 2m 26s\n",
      "52:\tlearn: 2.8665638\ttotal: 3m 24s\tremaining: 2m 22s\n",
      "53:\tlearn: 2.8645341\ttotal: 3m 28s\tremaining: 2m 18s\n",
      "54:\tlearn: 2.8626504\ttotal: 3m 32s\tremaining: 2m 14s\n",
      "55:\tlearn: 2.8612605\ttotal: 3m 35s\tremaining: 2m 11s\n",
      "56:\tlearn: 2.8589819\ttotal: 3m 39s\tremaining: 2m 7s\n",
      "57:\tlearn: 2.8583822\ttotal: 3m 43s\tremaining: 2m 3s\n",
      "58:\tlearn: 2.8578795\ttotal: 3m 47s\tremaining: 1m 59s\n",
      "59:\tlearn: 2.8557635\ttotal: 3m 51s\tremaining: 1m 55s\n",
      "60:\tlearn: 2.8532051\ttotal: 3m 55s\tremaining: 1m 51s\n",
      "61:\tlearn: 2.8510965\ttotal: 3m 58s\tremaining: 1m 47s\n",
      "62:\tlearn: 2.8505135\ttotal: 4m 3s\tremaining: 1m 44s\n",
      "63:\tlearn: 2.8495824\ttotal: 4m 6s\tremaining: 1m 40s\n",
      "64:\tlearn: 2.8483242\ttotal: 4m 10s\tremaining: 1m 36s\n",
      "65:\tlearn: 2.8472503\ttotal: 4m 14s\tremaining: 1m 32s\n",
      "66:\tlearn: 2.8458705\ttotal: 4m 18s\tremaining: 1m 28s\n",
      "67:\tlearn: 2.8447846\ttotal: 4m 22s\tremaining: 1m 24s\n",
      "68:\tlearn: 2.8443691\ttotal: 4m 26s\tremaining: 1m 21s\n",
      "69:\tlearn: 2.8428125\ttotal: 4m 30s\tremaining: 1m 17s\n",
      "70:\tlearn: 2.8421173\ttotal: 4m 34s\tremaining: 1m 13s\n",
      "71:\tlearn: 2.8410274\ttotal: 4m 38s\tremaining: 1m 9s\n",
      "72:\tlearn: 2.8406655\ttotal: 4m 42s\tremaining: 1m 5s\n",
      "73:\tlearn: 2.8391789\ttotal: 4m 46s\tremaining: 1m 1s\n",
      "74:\tlearn: 2.8380704\ttotal: 4m 50s\tremaining: 58.1s\n",
      "75:\tlearn: 2.8375138\ttotal: 4m 54s\tremaining: 54.2s\n",
      "76:\tlearn: 2.8364554\ttotal: 4m 58s\tremaining: 50.3s\n",
      "77:\tlearn: 2.8357463\ttotal: 5m 2s\tremaining: 46.5s\n",
      "78:\tlearn: 2.8348902\ttotal: 5m 5s\tremaining: 42.6s\n",
      "79:\tlearn: 2.8346811\ttotal: 5m 9s\tremaining: 38.7s\n",
      "80:\tlearn: 2.8337718\ttotal: 5m 13s\tremaining: 34.8s\n",
      "81:\tlearn: 2.8326092\ttotal: 5m 17s\tremaining: 31s\n",
      "82:\tlearn: 2.8316184\ttotal: 5m 21s\tremaining: 27.1s\n",
      "83:\tlearn: 2.8311743\ttotal: 5m 25s\tremaining: 23.2s\n",
      "84:\tlearn: 2.8305758\ttotal: 5m 29s\tremaining: 19.4s\n",
      "85:\tlearn: 2.8301281\ttotal: 5m 33s\tremaining: 15.5s\n",
      "86:\tlearn: 2.8295540\ttotal: 5m 36s\tremaining: 11.6s\n",
      "87:\tlearn: 2.8292193\ttotal: 5m 40s\tremaining: 7.74s\n",
      "88:\tlearn: 2.8284635\ttotal: 5m 44s\tremaining: 3.87s\n",
      "89:\tlearn: 2.8274479\ttotal: 5m 48s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "reg=CatBoostRegressor(iterations=90, depth=16, eta=0.3)\n",
    "reg.fit(X_trainval.to_numpy(), y_trainval)\n",
    "pred_test = np.clip(reg.predict(X_test.to_numpy()), 0, 20)\n",
    "write_predictions_by_array(pred_test[submissionidx2testidx], 'submission-catboost-feature_set_within-lr0.3.csv')\n",
    "# LB score 1.121911 and 1.11979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Kaggle-C1-text-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "22170b496ee045b3b9975d05b0a4d8e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47f2f9b1fadf44e7829b7a5dd04f994d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56c59abdf53e4ccfae147a1b1e8408eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_76ab44c3980e4b7c8d552d0a53195975",
       "IPY_MODEL_7f9d57175f6149d08092c23799891b34"
      ],
      "layout": "IPY_MODEL_f57a7b904c3d4c2ab82802e25b0b1b21"
     }
    },
    "76ab44c3980e4b7c8d552d0a53195975": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e308dc6f5047435b95ca5e6d036b2450",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2adb6d1bead4670ae9ce7c3e32590c7",
      "value": 4
     }
    },
    "7f9d57175f6149d08092c23799891b34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47f2f9b1fadf44e7829b7a5dd04f994d",
      "placeholder": "",
      "style": "IPY_MODEL_22170b496ee045b3b9975d05b0a4d8e7",
      "value": "100% 4/4 [00:45&lt;00:00, 11.42s/it]"
     }
    },
    "e308dc6f5047435b95ca5e6d036b2450": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2adb6d1bead4670ae9ce7c3e32590c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f57a7b904c3d4c2ab82802e25b0b1b21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
