{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vvivvi/kaggle-c1/blob/master/Kaggle_C1_text_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "CY0RZpd88blS",
    "outputId": "eeb875e8-6911-4c03-f3ef-1384b94be160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.18.1\n",
      "pandas 0.25.3\n",
      "scipy 1.4.1\n",
      "sklearn 0.22.1\n",
      "lightgbm 2.3.1\n",
      "catboost 0.22\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score\n",
    "import catboost\n",
    "import gc\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "for p in [np, pd, scipy, sklearn, lgb, catboost]:\n",
    "    print (p.__name__, p.__version__)\n",
    "    \n",
    "DATA_FOLDER = 'competitive-data-science-predict-future-sales'\n",
    "test_spec = pd.read_csv(os.path.join(DATA_FOLDER, 'test.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (0.22)\n",
      "Requirement already satisfied: graphviz in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from catboost) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from catboost) (3.2.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from catboost) (0.25.3)\n",
      "Requirement already satisfied: six in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from catboost) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from catboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: plotly in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from catboost) (4.5.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from matplotlib->catboost) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from matplotlib->catboost) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2019.3)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /home/vvi/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (46.0.0.post20200311)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xCDUSYw8rWZX"
   },
   "outputs": [],
   "source": [
    "def write_predictions_by_array(array, filename):\n",
    "  df=pd.DataFrame(array)\n",
    "  df.columns=['item_cnt_month']\n",
    "  df.to_csv(os.path.join(DATA_FOLDER, filename), index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hF4l3wSvb020"
   },
   "outputs": [],
   "source": [
    "def clipped_rmse(gt, predicted,clip_min=0, clip_max=20):\n",
    "  target=np.minimum(np.maximum(gt,clip_min), clip_max)\n",
    "  return np.sqrt((target-predicted)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KqlQS1ns8Ek"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WRUNk-tjMWby",
    "outputId": "66fa64a3-47f4-495b-94e1-fa248da5f864"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_cols=['item_id','shop_id','date_block_num']\n",
    "category_data=pd.read_csv(DATA_FOLDER + '/category.csv')\n",
    "lagged_basic=pd.read_csv(DATA_FOLDER + '/lagged_basic.csv') \n",
    "targets = pd.read_csv(DATA_FOLDER + '/targets.csv') \n",
    "all_data = pd.merge(category_data, lagged_basic, on=index_cols)\n",
    "all_data = pd.merge(all_data, targets, on=index_cols)\n",
    "\n",
    "all_data=downcast_dtypes(all_data)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'shop_id', 'item_id', 'date_block_num',\n",
       "       'item_category_id', 'item_name_category_tfidf_unigram_32',\n",
       "       'item_name_category_tfidf_unigram_256',\n",
       "       'item_name_category_tfidf_bigram_32',\n",
       "       'item_name_category_tfidf_bigram_256', 'item_name_category_frequent_32',\n",
       "       'item_name_category_frequent_256'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRDS7n-aTPL3"
   },
   "outputs": [],
   "source": [
    "dates = all_data['date_block_num']\n",
    "\n",
    "date_block_val = 33\n",
    "date_block_test = 35 # Dec 2015\n",
    "\n",
    "dates_train = dates[dates <  date_block_val]\n",
    "dates_val  = dates[dates == date_block_val]\n",
    "dates_test  = dates[dates == date_block_test]\n",
    "\n",
    "to_drop_cols=[col for col in all_data.columns.values if ((re.search('^target_',col) and not re.search('lag',col)) or re.search('Unnamed',col)) ]\n",
    "\n",
    "#X_train = all_data.loc[dates <  date_block_val, to_keep_cols]\n",
    "#X_val =  all_data.loc[dates == date_block_val, to_keep_cols]\n",
    "#X_trainval =  all_data.loc[dates < date_block_test, to_keep_cols]\n",
    "#X_test =  all_data.loc[dates == date_block_test, to_keep_cols]\n",
    "\n",
    "y_train = np.clip(all_data.loc[dates <  date_block_val, 'target'].values,0,20)\n",
    "y_trainval = np.clip(all_data.loc[dates <  date_block_test, 'target'].values,0,20)\n",
    "y_val =  np.clip(all_data.loc[dates == date_block_val, 'target'].values,0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out mapping from test data indices to submission ids\n",
    "\n",
    "shop_item2submissionid={}\n",
    "for idx, row in test_spec.iterrows():\n",
    "    shop_item2submissionid[str(row['shop_id'])+'_'+str(row['item_id'])] = row['ID']\n",
    "    \n",
    "test_data=all_data.loc[dates == date_block_test, ['shop_id','item_id']]    \n",
    "    \n",
    "testidx2submissionidx=np.zeros(test_data.shape[0], dtype=np.int32)\n",
    "for idx in range(test_data.shape[0]):\n",
    "    row =test_data.iloc[idx]\n",
    "    testidx2submissionidx[idx] = shop_item2submissionid[str(row['shop_id'])+'_'+str(row['item_id'])]\n",
    "    \n",
    "print(len(testidx2submissionidx))    \n",
    "\n",
    "#invert the mapping\n",
    "submissionidx2testidx=np.zeros(test_data.shape[0], dtype=np.int32)\n",
    "for i in range(test_data.shape[0]):\n",
    "    submissionidx2testidx[testidx2submissionidx[i]]=i\n",
    "    \n",
    "del test_data\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yUhefAJCgI4w",
    "outputId": "1a98c58b-7e98-40a4-8c13-34f9aae62d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation R-squared for LightGBM is 0.197921\n",
      "Clipped RMSE of lgb predictions is  0.40996664568708163\n"
     ]
    }
   ],
   "source": [
    "to_keep_cols = ['shop_id','item_id','item_category_id']\n",
    "# to_keep_cols = [col for col in to_keep_cols if not re.search('name',col)]\n",
    "to_keep_cols = [i for i in to_keep_cols if not i in to_drop_cols]\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':2\n",
    "              }\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_val, to_keep_cols], label=y_train), 100)\n",
    "pred_lgb_val = np.clip(model.predict(all_data.loc[dates ==  date_block_val, to_keep_cols]), 0, 20)\n",
    "print('Validation R-squared for LightGBM is %f' % r2_score(y_val, pred_lgb_val))\n",
    "print('Clipped RMSE of lgb predictions is ', clipped_rmse(y_val, pred_lgb_val))\n",
    "# Validation R-squared for LightGBM is 0.197921\n",
    "# Clipped RMSE of lgb predictions is  0.40996664568708163\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_test, to_keep_cols], label=y_trainval), 100)\n",
    "pred_lgb_test = np.clip(model.predict(all_data.loc[dates ==  date_block_test, to_keep_cols]), 0, 20)\n",
    "write_predictions_by_array(pred_lgb_test[submissionidx2testidx], 'submission-lgb-basic-categries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yUhefAJCgI4w",
    "outputId": "1a98c58b-7e98-40a4-8c13-34f9aae62d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation R-squared for LightGBM is 0.068788\n",
      "Clipped RMSE of lgb predictions is  0.45511637813975203\n"
     ]
    }
   ],
   "source": [
    "to_keep_cols = [col for col in all_data.columns.values if re.search('name',col)]\n",
    "to_keep_cols = [i for i in to_keep_cols if not i in to_drop_cols]\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':2\n",
    "              }\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_val, to_keep_cols], label=y_train), 100)\n",
    "pred_lgb_val = np.clip(model.predict(all_data.loc[dates ==  date_block_val, to_keep_cols]), 0, 20)\n",
    "print('Validation R-squared for LightGBM is %f' % r2_score(y_val, pred_lgb_val))\n",
    "print('Clipped RMSE of lgb predictions is ', clipped_rmse(y_val, pred_lgb_val))\n",
    "# Validation R-squared for LightGBM is 0.068788\n",
    "# Clipped RMSE of lgb predictions is  0.45511637813975203\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_test, to_keep_cols], label=y_trainval), 100)\n",
    "pred_lgb_test = np.clip(model.predict(all_data.loc[dates ==  date_block_test, to_keep_cols]), 0, 20)\n",
    "write_predictions_by_array(pred_lgb_test[submissionidx2testidx], 'submission-lgb-text-categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yUhefAJCgI4w",
    "outputId": "1a98c58b-7e98-40a4-8c13-34f9aae62d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation R-squared for LightGBM is 0.218179\n",
      "Clipped RMSE of lgb predictions is  0.40772495453592217\n"
     ]
    }
   ],
   "source": [
    "to_keep_cols = [col for col in all_data.columns.values if re.search('name',col)]\n",
    "to_keep_cols += ['shop_id','item_id','item_category_id']\n",
    "to_keep_cols = [i for i in to_keep_cols if not i in to_drop_cols]\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':2\n",
    "              }\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_val, to_keep_cols], label=y_train), 100)\n",
    "pred_lgb_val = np.clip(model.predict(all_data.loc[dates ==  date_block_val, to_keep_cols]), 0, 20)\n",
    "print('Validation R-squared for LightGBM is %f' % r2_score(y_val, pred_lgb_val))\n",
    "print('Clipped RMSE of lgb predictions is ', clipped_rmse(y_val, pred_lgb_val))\n",
    "\n",
    "# Validation R-squared for LightGBM is 0.218179\n",
    "# Clipped RMSE of lgb predictions is  0.40772495453592217\n",
    "\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_test, to_keep_cols], label=y_trainval), 100)\n",
    "pred_lgb_test = np.clip(model.predict(all_data.loc[dates ==  date_block_test, to_keep_cols]), 0, 20)\n",
    "write_predictions_by_array(pred_lgb_test[submissionidx2testidx], 'submission-lgb-basic-and-text-categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yUhefAJCgI4w",
    "outputId": "1a98c58b-7e98-40a4-8c13-34f9aae62d73"
   },
   "outputs": [],
   "source": [
    "to_keep_cols = [c for c in all_data.columns.values if re.search('lag',c)]\n",
    "# to_keep_cols = [col for col in to_keep_cols if not re.search('name',col)]\n",
    "to_keep_cols = [i for i in to_keep_cols if not i in to_drop_cols]\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':2\n",
    "              }\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_val, to_keep_cols], label=y_train), 200)\n",
    "pred_lgb_val = np.clip(model.predict(all_data.loc[dates ==  date_block_val, to_keep_cols]), 0, 20)\n",
    "print('Validation R-squared for LightGBM is %f' % r2_score(y_val, pred_lgb_val))\n",
    "print('Clipped RMSE of lgb predictions is ', clipped_rmse(y_val, pred_lgb_val))\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_test, to_keep_cols], label=y_trainval), 200)\n",
    "pred_lgb_test = np.clip(model.predict(all_data.loc[dates ==  date_block_test, to_keep_cols]), 0, 20)\n",
    "write_predictions_by_array(pred_lgb_test[submissionidx2testidx], 'submission-lgb-basic-lagged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yUhefAJCgI4w",
    "outputId": "1a98c58b-7e98-40a4-8c13-34f9aae62d73"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-f2c6d42c1784>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-f2c6d42c1784>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    Validation R-squared for LightGBM is 0.335086\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "to_keep_cols = [c for c in all_data.columns.values if re.search('lag',c)] + ['shop_id','item_id','item_category_id']\n",
    "# to_keep_cols = [col for col in to_keep_cols if not re.search('name',col)]\n",
    "to_keep_cols = [i for i in to_keep_cols if not i in to_drop_cols]\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':2\n",
    "              }\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_val, to_keep_cols], label=y_train), 100)\n",
    "pred_lgb_val = np.clip(model.predict(all_data.loc[dates ==  date_block_val, to_keep_cols]), 0, 20)\n",
    "print('Validation R-squared for LightGBM is %f' % r2_score(y_val, pred_lgb_val))\n",
    "print('Clipped RMSE of lgb predictions is ', clipped_rmse(y_val, pred_lgb_val))\n",
    "# Validation R-squared for LightGBM is 0.335086\n",
    "#Clipped RMSE of lgb predictions is  0.35535191672828514\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_test, to_keep_cols], label=y_trainval), 100)\n",
    "pred_lgb_test = np.clip(model.predict(all_data.loc[dates ==  date_block_test, to_keep_cols]), 0, 20)\n",
    "write_predictions_by_array(pred_lgb_test[submissionidx2testidx], 'submission-lgb-basic-and-lagged.csv')\n",
    "# LB 1.027 / 1.024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yUhefAJCgI4w",
    "outputId": "1a98c58b-7e98-40a4-8c13-34f9aae62d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation R-squared for LightGBM is 0.364015\n",
      "Clipped RMSE of lgb predictions is  0.3477432847525624\n"
     ]
    }
   ],
   "source": [
    "to_keep_cols = [c for c in all_data.columns.values if re.search('lag',c)] + ['shop_id','item_id','item_category_id']\n",
    "to_keep_cols += [col for col in all_data.columns.values if re.search('name',col)]\n",
    "# to_keep_cols = [col for col in to_keep_cols if not re.search('name',col)]\n",
    "to_keep_cols = [i for i in to_keep_cols if not i in to_drop_cols]\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':2\n",
    "              }\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_val, to_keep_cols], label=y_train), 100)\n",
    "pred_lgb_val = np.clip(model.predict(all_data.loc[dates ==  date_block_val, to_keep_cols]), 0, 20)\n",
    "print('Validation R-squared for LightGBM is %f' % r2_score(y_val, pred_lgb_val))\n",
    "print('Clipped RMSE of lgb predictions is ', clipped_rmse(y_val, pred_lgb_val))\n",
    "# Validation R-squared for LightGBM is 0.364015\n",
    "# Clipped RMSE of lgb predictions is  0.3477432847525624\n",
    "model = lgb.train(lgb_params, lgb.Dataset(all_data.loc[dates <  date_block_test, to_keep_cols], label=y_trainval), 100)\n",
    "pred_lgb_test = np.clip(model.predict(all_data.loc[dates ==  date_block_test, to_keep_cols]), 0, 20)\n",
    "write_predictions_by_array(pred_lgb_test[submissionidx2testidx], 'submission-lgb-basic-and-lagged-and-text-categories.csv')\n",
    "# LB scores are: 0.956601 and 0.95988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "to_keep_cols = [col for col in all_data.columns.values if  re.search('lag',col)]\n",
    "# to_keep_cols = [col for col in to_keep_cols if not re.search('name',col)]\n",
    "to_keep_cols = [i for i in to_keep_cols if not i in to_drop_cols]\n",
    "\n",
    "model=CatBoostRegressor(iterations=1000, task_type='GPU')\n",
    "model.fit(all_data.loc[dates <  date_block_val, to_keep_cols].values, y_train, verbose=1)\n",
    "pred_val = np.clip(model.predict(all_data.loc[dates ==  date_block_val, to_keep_cols].values), 0, 20)\n",
    "print('Validation R-squared for LassoLars model is %f' % r2_score(y_val, pred_val))\n",
    "print('Clipped RMSE of LassoLars predictions is ', clipped_rmse(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "5zy8DZ_7a0Wf",
    "outputId": "4f991e08-b30a-4b80-d7cf-eb5929c236c4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Kaggle-C1-text-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "22170b496ee045b3b9975d05b0a4d8e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47f2f9b1fadf44e7829b7a5dd04f994d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56c59abdf53e4ccfae147a1b1e8408eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_76ab44c3980e4b7c8d552d0a53195975",
       "IPY_MODEL_7f9d57175f6149d08092c23799891b34"
      ],
      "layout": "IPY_MODEL_f57a7b904c3d4c2ab82802e25b0b1b21"
     }
    },
    "76ab44c3980e4b7c8d552d0a53195975": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e308dc6f5047435b95ca5e6d036b2450",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2adb6d1bead4670ae9ce7c3e32590c7",
      "value": 4
     }
    },
    "7f9d57175f6149d08092c23799891b34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47f2f9b1fadf44e7829b7a5dd04f994d",
      "placeholder": "​",
      "style": "IPY_MODEL_22170b496ee045b3b9975d05b0a4d8e7",
      "value": "100% 4/4 [00:45&lt;00:00, 11.42s/it]"
     }
    },
    "e308dc6f5047435b95ca5e6d036b2450": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2adb6d1bead4670ae9ce7c3e32590c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f57a7b904c3d4c2ab82802e25b0b1b21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
